{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the previous mission, we tried to optimize our predictions by creating and selecting the features used to train\n",
    "#our model. Maybe changing ml model will help us out also.\n",
    "\n",
    "#So far, we've been using the logistic regression algorithm to train our models, however there are hundreds of\n",
    "#different machine learning algorithms from which we can choose. Each algorithm has different strengths and weaknesses,\n",
    "#and so we need to select the algorithm that works best with our specific data— in this case our Kaggle competition.\n",
    "\n",
    "#The process of selecting the algorithm which gives the best predictions for your data is called \"MODEL SELECTION\"\n",
    "#we're going work with two new algorithms: k-nearest neighbors and random forests.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code snippet:\n",
    "import pandas as pd\n",
    "train = pd.read_csv('train_modified.csv')\n",
    "holdout = pd.read_csv('holdout_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We're going to train our models using all the columns in the train dataframe. This will cause a small amount of\n",
    "#overfitting due to collinearity (as we discussed in the previous mission), but having more features will allow us to\n",
    "#more thoroughly compare algorithms.\n",
    "\n",
    "#So we have something to compare to, we're going to train a logistic regression model. We'll use cross validation to\n",
    "#get a baseline score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76666667 0.82222222 0.78651685 0.87640449 0.83146067 0.80898876\n",
      " 0.82022472 0.82022472 0.85393258 0.85227273] \n",
      " 0.823891442515038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#code snippet:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "all_X = train.drop(['Survived','PassengerId'],axis=1)\n",
    "all_y = train['Survived']\n",
    "\n",
    "lr=LogisticRegression()\n",
    "scores=cross_val_score(lr,all_X,all_y,cv=10)\n",
    "accuracy_lr=scores.mean()\n",
    "print(scores,\"\\n\",accuracy_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Model using K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The logistic regression baseline model from the previous screen scored 82.4%.\n",
    "\n",
    "# Model\tCross-validation score\tKaggle score\n",
    "# Previous best Kaggle score\t82.3%\t78.0%\n",
    "# Logistic regression baseline\t82.4%\t?\n",
    "\n",
    "#The logistic regression algorithm works by calculating linear rships between the features and the target variable and\n",
    "#using those to make predictions. Let's look at an algorithm that makes predictions using a different method.\n",
    "\n",
    "#The k-nearest neighbors algorithm finds the observations in our training set most similar to the observation in our\n",
    "#test set, and uses the average outcome of those 'neighbor' observations to make a prediction. The 'k' is the number\n",
    "#of neighbor observations used to make the prediction.\n",
    "\n",
    "#If you'd like to learn more about the k-nearest neighbors algorithm, you might like to check out doc about KNeighborsC\n",
    "#lassifier\n",
    "\n",
    "#Just like it does for logistic regression, scikit-learn has a class that makes it easy to use k-nearest neighbors to\n",
    "#make predictions, neighbors.KNeighborsClassifier.\n",
    "\n",
    "#The optional n_neighbors argument sets the value of k when predictions are made. The default value of n_neighbors is 5\n",
    "# but we're going to start by building a simple model that uses the closest neighbor to make our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857382816933379"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code snippet:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "scores = cross_val_score(knn, all_X, all_y, cv=10)\n",
    "accuracy_knn = scores.mean()\n",
    "accuracy_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Different K Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The k-nearest neighbors model we trained in the previous screen had an accuracy score of 78.6%, worse than our\n",
    "#baseline score of 82.4%.\n",
    "\n",
    "# Model\tCross-validation score\tKaggle score\n",
    "# Previous best Kaggle score\t82.3%\t78.0%\n",
    "# Logistic regression baseline\t82.4%\t?\n",
    "# K-nearest neighbors, k == 1\t78.6%\t?\n",
    "\n",
    "#Besides default settings, we can vary the settings of each model— for instance the value of k in our k-nearest\n",
    "#neighbors model. This is called hyperparameter optimization.\n",
    "\n",
    "#We can use a loop and Python's inbuilt range() class to iterate through different values for k and calculate the\n",
    "#accuracy score for each different value. We will only want to test odd values for k to avoid ties,where both 'survived\n",
    "#and 'died' outcomes would have the same number of neighbors.\n",
    "\n",
    "#Let's use this technique to calculate the accuracy of our model for values of k from 1-49, storing the results in a\n",
    "#dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#code snippet:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_dict(dictionary):\n",
    "    pd.Series(dictionary).plot.bar(figsize=(9,6),\n",
    "                                   ylim=(0.78,0.83),rot=0)\n",
    "    plt.show()\n",
    "\n",
    "knn_scores = dict()\n",
    "for k in range(1,50,2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    scores = cross_val_score(knn, all_X, all_y, cv=10)\n",
    "    accuracy_knn = scores.mean()\n",
    "    knn_scores[k] = accuracy_knn\n",
    "\n",
    "plot_dict(knn_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 19}\n",
      "0.8237934904601572\n"
     ]
    }
   ],
   "source": [
    "#Looking at our plot from the previous screen we can see that a k value of 19 gave us our best score, and checking the\n",
    "#knn_scores dictionary we can see that the score was 82.4%, identical to our baseline (if we didn't round the numbers\n",
    "#you would see that it's actually 0.01% less accurate).\n",
    "\n",
    "# Model\tCross-validation score\tKaggle score\n",
    "# Previous best Kaggle score\t82.3%\t78.0%\n",
    "# Logistic regression baseline\t82.4%\t?\n",
    "# K-nearest neighbors, k == 1\t78.6%\t?\n",
    "# K-nearest neighbors, k == 19\t82.4%\t?\n",
    "\n",
    "#The technique we just used is called grid search - we train a number of models across a 'grid' of values and then\n",
    "#searched for the model that gave us the highest accuracy.Sklearn has a class to perform grid search, model_selection\n",
    "#GridSearchCV(). The 'CV' in the name indicates that we're performing both grid search and cross val at the same time.\n",
    "\n",
    "#By creating a dictionary of parameters and possible values and passing it to the GridSearchCV object we can automate\n",
    "#the process. Here's what the code from the prev screen would look like, when implemented using the GridSearchCV class.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "hyperparameters = {\n",
    "    \"n_neighbors\": range(1,50,2)\n",
    "}\n",
    "grid = GridSearchCV(knn, param_grid=hyperparameters, cv=10)\n",
    "grid.fit(all_X, all_y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n",
    "#Our final step was to print the GridSearchCV.best_params_ and GridSearchCV.best_score_ attr to retrieve the params\n",
    "#of the best-performing model, and the score it achieved.\n",
    "\n",
    "#We can also use GridSearchCV to try combinations of different hyperparameters. Say we wanted to test values of\n",
    "#3 dif tree algorithms. for the algorithm parameter and values of 1, 3, and 5 for the n_neighbors algo\n",
    "#parameter. GridSearchCV would train and test 9 models (3 for the first hyperparameter times 3 for the second hyperparameter\n",
    "#shown in the diagram below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'brute', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n",
      "0.8282828282828283\n"
     ]
    }
   ],
   "source": [
    "#code snippet:\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparameters = {\n",
    "    \"n_neighbors\": range(1,20,2),\n",
    "    \"weights\": [\"distance\", \"uniform\"],\n",
    "    \"algorithm\": ['brute'],\n",
    "    \"p\": [1,2]\n",
    "}\n",
    "knn = KNeighborsClassifier()\n",
    "grid = GridSearchCV(knn,param_grid=hyperparameters,cv=10)\n",
    "\n",
    "grid.fit(all_X, all_y)\n",
    "\n",
    "best_params = grid.best_params_\n",
    "best_score = grid.best_score_\n",
    "\n",
    "print(best_params)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting KNN Predictions to Kaggle - Attempt2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=1,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The cross-validation score for the best performing model was 82.7%, better than our baseline model.\n",
    "\n",
    "# Model\tCross-validation score\tKaggle score\n",
    "# Previous best Kaggle score\t82.3%\t78.0%\n",
    "# Logistic regression baseline\t82.4%\t?\n",
    "# K-nearest neighbors, k == 1\t78.6%\t?\n",
    "# K-nearest neighbors, k == 19\t82.4%\t?\n",
    "# K-nearest neighbors, best model from grid search\t82.7%\t?\n",
    "\n",
    "#We can use the GridSearchCV.best_estimator_ attribute to retrieve a trained model with the best-performing hyperparams\n",
    "best_knn = grid.best_estimator_\n",
    "#is equivalent to this code where we manually specify the hyperparameters and train the model:\n",
    "best_knn = KNeighborsClassifier(p=1,algorithm='brute',n_neighbors=5,weights='uniform')\n",
    "best_knn.fit(all_X,all_y)\n",
    "\n",
    "#Lets use that model to make preds on the holdout set, submit those preds to Kaggle to see if we have improved overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code snippet:\n",
    "holdout_no_id = holdout.drop(['PassengerId'],axis=1)\n",
    "best_knn = grid.best_estimator_\n",
    "holdout_predictions = best_knn.predict(holdout_no_id)\n",
    "\n",
    "holdout_ids = holdout[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": holdout_ids,\n",
    "                 \"Survived\": holdout_predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv(\"submission_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When we submit this(knn besthyper,best k attempt) to Kaggle,we'll see it scores 75.6%, less than our best submission\n",
    "#of 78.0%. While our model could be overfitting due to including all columns, it also seems like k-nearest neighbors\n",
    "#may not be the best algorithm choice.\n",
    "\n",
    "# Model\tCross-validation score\tKaggle score\n",
    "# Previous best Kaggle score\t82.3%\t78.0%\n",
    "# Logistic regression baseline\t82.4%\t\n",
    "# K-nearest neighbors, k == 1\t78.6%\t\n",
    "# K-nearest neighbors, k == 19\t82.4%\t\n",
    "# K-nearest neighbors, best model from grid search\t82.8%\t75.6%\n",
    "\n",
    "#Let's try another algorithm called random forests. Random forests is a specific type of decision tree algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8070125411417546"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code snippet:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=1)\n",
    "scores = cross_val_score(clf, all_X, all_y, cv=10)\n",
    "accuracy_rf = scores.mean()\n",
    "accuracy_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning our Random Forests Model with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the default settings, our random forests model obtained a cross validation score of 80.7%.\n",
    "\n",
    "# Model\tCross-validation score\tKaggle score\n",
    "# Previous best Kaggle score\t82.3%\t78.0%\n",
    "# Logistic regression baseline\t82.4%\t?\n",
    "# K-nearest neighbors, k == 1\t78.6%\t?\n",
    "# K-nearest neighbors, k == 19\t82.4%\t?\n",
    "# K-nearest neighbors, best model from grid search\t82.8%\t75.6%\n",
    "# Random forests, default hyperparameters\t80.7%\t?\n",
    "\n",
    "#Just like we did with the k-nearest neighbors model, we can use GridSearchCV to test a variety of hyperparams to find\n",
    "#the best performing model.\n",
    "\n",
    "#The best way to see a list of available hyperparameters is by checking the documentation for the classifier— in this\n",
    "#case, the doc for RandomForestClassifier. Let's use grid search to test out combinations of the following hyperparams:\n",
    "\n",
    "# criterion: \"entropy\" or \"gini\"\n",
    "# max_depth: 5 or 10\n",
    "# max_features: \"log2\" or \"sqrt\"\n",
    "# min_samples_leaf: 1 or 5\n",
    "# min_samples_split: 3 or 5\n",
    "# n_estimators: 6 or 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9}\n",
      "0.8428731762065096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berka\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#code snippet:\n",
    "hyperparameters = {\"criterion\": [\"entropy\", \"gini\"],\n",
    "                   \"max_depth\": [5, 10],\n",
    "                   \"max_features\": [\"log2\", \"sqrt\"],\n",
    "                   \"min_samples_leaf\": [1, 5],\n",
    "                   \"min_samples_split\": [3, 5],\n",
    "                   \"n_estimators\": [6, 9]\n",
    "}\n",
    "\n",
    "clf = RandomForestClassifier(random_state=1)\n",
    "grid = GridSearchCV(clf,param_grid=hyperparameters,cv=10)\n",
    "\n",
    "grid.fit(all_X, all_y)\n",
    "\n",
    "best_params = grid.best_params_\n",
    "best_score = grid.best_score_\n",
    "\n",
    "print(best_params)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Random Forest Predictions to Kaggle - Attempt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The cross-validation score for the best performing model was 84.3%, making it the best cv score we've obtained \n",
    "#Let's train it on the holdout data and create a submission file to see how it performs on the Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `GridSearchCV` object is stored in memory from\n",
    "# the previous screen with the variable name `grid`\n",
    "best_rf = grid.best_estimator_\n",
    "holdout_predictions = best_rf.predict(holdout_no_id)\n",
    "\n",
    "holdout_ids = holdout[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": holdout_ids,\n",
    "                 \"Survived\": holdout_predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv(\"submission_2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
